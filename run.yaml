version: '2'
image_name: llama-stack-local
apis:
  - inference
  - safety
  - vector_io

external_providers_dir: ./resources/external_providers

inference_store:
  type: sqlite
  db_path: /tmp/inference_store.db

metadata_store:
  type: sqlite
  db_path: /tmp/registry.db

providers:
  inference:
    - provider_id: openai
      provider_type: remote::openai
      config:
        api_key: ${OPENAI_API_KEY}
  
  safety:
    - provider_id: lightspeed_question_validity
      provider_type: inline::lightspeed_question_validity
      config:
        model_id: openai/gpt-4o
        temperature: 0.0
        invalid_question_response: |
          Hi, I'm the OpenShift Lightspeed assistant, I can help you with questions about OpenShift, 
          please ask me a question related to OpenShift.
  
  vector_io:
    - provider_id: solr_vector
      provider_type: remote::solr-vector-io
      config:
        solr_url: "http://localhost:8983/solr"
        collection_name: "portal"
        vector_field: "chunk_vector"
        content_field: "chunk"
        id_field: "chunk_id"
        embedding_dimension: 384
        persistence:
          type: sqlite
          namespace: portal_rag
        chunk_window_config:
          chunk_parent_id_field: "parent_id"
          chunk_index_field: "chunk_index"
          chunk_token_count_field: "num_tokens"
          parent_total_chunks_field: "total_chunks"
          parent_total_tokens_field: "total_tokens"
          parent_content_id_field: "doc_id"
          parent_content_title_field: "title"
          parent_content_url_field: "reference_url"
          chunk_filter_query: "is_chunk:true"

vector_stores:
  - vector_db_id: portal
    provider_id: solr_vector

models:
  - model_id: gpt-4o
    provider_id: openai
    model_type: llm
    provider_model_id: gpt-4o

shields:
  - shield_id: lightspeed_question_validity-shield
    provider_id: lightspeed_question_validity

server:
  host: 0.0.0.0
  port: 8321

logging:
  level: DEBUG