version: 2
image_name: llama-stack-local
apis:
  - inference
  - safety
  - vector_io
  - agents
  - tool_runtime
  - vector_io
  - files

external_providers_dir: ./resources/external_providers

storage:
  backends:
    kv_default:
      type: kv_sqlite
      db_path: ${env.KV_STORE_PATH:=~/.llama/storage/rag/kv_store.db}
    sql_default:
      type: sql_sqlite
      db_path: ${env.SQL_STORE_PATH:=~/.llama/storage/sql_store.db}
    byok_openshift-docs_storage:
      db_path: /Users/cpompeia/Documents/Dev/rag-content/generated_stores/os-start/faiss_store.db
      type: kv_sqlite
  stores:
    metadata:
      namespace: registry
      backend: kv_default
    inference:
      table_name: inference_store
      backend: sql_default
    conversations:
      table_name: openai_conversations
      backend: sql_default
    prompts:
      namespace: prompts
      backend: kv_default

providers:

  files:
    - provider_id: meta-reference-files
      provider_type: inline::localfs
      config:
        storage_dir: ${env.FILES_STORAGE_DIR:=/tmp/llama_files}
        metadata_store:
          table_name: files_metadata
          backend: sql_default

  inference:
    - provider_id: openai
      provider_type: remote::openai
      config:
        api_key: ${env.OPENAI_API_KEY}
    - config: {}
      provider_id: sentence-transformers
      provider_type: inline::sentence-transformers

  safety:
    - provider_id: lightspeed_question_validity
      provider_type: inline::lightspeed_question_validity
      config:
        model_id: openai/gpt-4o-mini
        temperature: 0.0
        invalid_question_response: |
          Hi, I'm the OpenShift Lightspeed assistant, I can help you with questions about OpenShift,
          please ask me a question related to OpenShift.

    - provider_id: lightspeed_redaction
      provider_type: inline::lightspeed_redaction
      config:
        case_sensitive: false
        rules:
          - pattern: "(?i)(password|passwd)[\\s:=]+[^\\s]+"
            replacement: "[REDACTED_PASSWORD]"
          - pattern: "(?i)(api_key|secret|token)[\\s:=]+[a-zA-Z0-9\\-_]{16,}"
            replacement: "[REDACTED_SECRET]"
          - pattern: "\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b"
            replacement: "[REDACTED_EMAIL]"

  vector_io:
    - config:
        persistence:
          backend: byok_openshift-docs_storage
          namespace: vector_io::faiss
      provider_id: byok_openshift-docs
      provider_type: inline::faiss
    - provider_id: okp_solr
      provider_type: remote::solr-vector-io
      config:
        solr_url: "http://localhost:8983/solr"
        collection_name: "portal"
        vector_field: "chunk_vector"
        content_field: "chunk"
        id_field: "chunk_id"
        embedding_dimension: 384
        persistence:
          type: sqlite
          namespace: portal_rag
        chunk_window_config:
          chunk_parent_id_field: "parent_id"
          chunk_index_field: "chunk_index"
          chunk_token_count_field: "num_tokens"
          parent_total_chunks_field: "total_chunks"
          parent_total_tokens_field: "total_tokens"
          parent_content_id_field: "doc_id"
          parent_content_title_field: "title"
          parent_content_url_field: "reference_url"
          chunk_filter_query: "is_chunk:true"

  tool_runtime:
    - provider_id: model-context-protocol
      provider_type: remote::model-context-protocol
      config: {}
    - config: {}
      provider_id: rag-runtime
      provider_type: inline::rag-runtime

  agents:
    - provider_id: lightspeed_inline_agent
      provider_type: inline::lightspeed_inline_agent
      config:
        persistence:
          agent_state:
            namespace: lightspeed_agents
            backend: kv_default
          responses:
            table_name: lightspeed_responses
            backend: sql_default
        tools_filter:
          enabled: true
          model_id: openai/gpt-4o-mini
          min_tools: 10
          always_include_tools:
            - knowledge_search
        chatbot_temperature_override: 1.0

registered_resources:

  models:
    - metadata:
        embedding_dimension: 768
      model_id: byok_openshift-docs_embedding
      model_type: embedding
      provider_id: sentence-transformers
      provider_model_id: <path_to>/embeddings_model

  shields:
    - shield_id: lightspeed_question_validity-shield
      provider_id: lightspeed_question_validity
    - shield_id: redaction-shield
      provider_id: lightspeed_redaction
      provider_shield_id: lightspeed-redaction-shield

  tool_groups:
    - toolgroup_id: openshift-tools
      provider_id: model-context-protocol
      mcp_endpoint:
        uri: http://localhost:8401/sse
    - provider_id: rag-runtime
      toolgroup_id: builtin::rag

  vector_stores:
    - embedding_dimension: 768
      embedding_model: sentence-transformers/<path_to>/embeddings_model
      provider_id: byok_openshift-docs
      vector_store_id: vs_123
    - embedding_dimension: 384
      embedding_model: sentence-transformers/ibm-granite/granite-embedding-30m-english
      provider_id: okp_solr
      vector_store_id: portal-rag

server:
  host: 0.0.0.0
  port: 8321

logging:
  level: DEBUG

vector_stores:
  default_provider_id: faiss
  default_embedding_model:
    provider_id: sentence-transformers
    model_id: nomic-ai/nomic-embed-text-v1.5
